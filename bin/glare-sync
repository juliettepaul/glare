#!/bin/bash

# Defaults
USAGE_TXT="Usage $0 -t|--target-dir <target folder> -d|--download-dir <temporary directory for downloading> -s|--server <server uri for images>"

# So your friends can edit these files too
umask 002

if [[ -e /etc/glare.conf ]]; then
    source /etc/glare.conf
fi

if [[ -e ~/.glare.conf ]]; then
    source ~/.glare.conf
fi

# Argument overrides
ARGS=$(getopt -o t:d:s:h -l "target-dir:,download-dir:,server:,help" -n "$(basename $0)" -- "$@");
if [ $? -ne 0 ];
then
    exit 1
fi

eval set -- "$ARGS";
while true; do
    case "$1" in
        -t|--target-dir)
            shift;
            if [ -n "$1" ]; then
                TARGET_DIR=$1
                shift;
            fi
            ;;
        -d|--download-dir)
            shift;
            if [ -n "$1" ]; then
                DOWNLOAD_DIR=$1
                shift;
            fi
            ;;
        -s|--server)
            shift;
            if [ -n "$1" ]; then
                SERVER=$1
                shift;
            fi
            ;;
        -h|--help)
            echo "$USAGE_TXT"
            exit;
            ;;
        --)
            shift;
      break;
      ;;
  esac
done

if [ -z $TARGET_DIR ]; then
    echo "You must specify a target directory"
    exit 2
fi

if [ -z $SERVER ]; then
    echo "You must specify a server for images"
    exit 3
fi

if [ -z $DOWNLOAD_DIR ]; then
    DOWNLOAD_DIR="/tmp"
fi

# Create template directory
mkdir -p $TARGET_DIR
# Create temporary download dir
mkdir -p $DOWNLOAD_DIR
# Hard link all current copies of templates (used later with wget option --unlink to provide atomic downloads)
for i in $(ls $TARGET_DIR); do ln -f $TARGET_DIR/$i $DOWNLOAD_DIR/$i; done
IMAGE_LIST=$(curl $SERVER/images.txt)
# Download images that are out of date unlinking ones it clobbers without changing anything in live template directory
for image in $IMAGE_LIST; do (cd $DOWNLOAD_DIR && wget -nH --cut-dirs=1 --unlink -N $SERVER/$image); done
# Atomically hard link all changed images
for i in $(ls $DOWNLOAD_DIR); do ln -f $DOWNLOAD_DIR/$i $TARGET_DIR/$i; done
# Clean up download dir
rm -rf $DOWNLOAD_DIR
